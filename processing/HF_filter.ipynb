{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2fd208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d5932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Unkarlslyan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=project>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf().setAppName('project')\n",
    "sc = SparkContext(conf=conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd3a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('project').config('spark.some.config.option', \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd3e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd10 = ['I501', 'I5020', 'I5021', 'I5022', 'I5023', 'I5030', 'I5031', 'I5032', 'I5033', 'I5040', 'I5041', 'I5042', 'I5043', 'I509',  'I50810','I50811', 'I50812', 'I50813', 'I50814', 'I5082', 'I5083', 'I5084', 'I5089',  'I42', 'I420', 'I423', 'I424', 'I425', 'I426', 'I427', 'I428', 'I429', '143', '1430', '1431', '1432', '1438',  'I110']\n",
    "icd09 = ['4280', '4281', '42820', '42821', '42822', '42823', '42830', '42831' ,'42832', '42833', '42840', '42841' ,'42842', '42843','4289']\n",
    "icd = icd09+icd10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf01c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'mimic-iv-1.0\\hosp\\diagnoses_icd.csv'\n",
    "#df = pd.read_csv(path)\n",
    "df_icd = spark.read.csv(path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b9d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icd2 = df_icd.filter(df_icd.icd_code.isin(icd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80bd129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subject_ids = df_icd2.select('subject_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5d8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = df_subject_ids.select(\"subject_id\").toPandas()\n",
    "subject_ids = subject_ids.subject_id.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514789a5",
   "metadata": {},
   "source": [
    "## csvs that have icd code in hosp:\n",
    "d_icd_diagnoses, d_icd_procedures, diagnoses_icd, procedures_icd\n",
    "\n",
    "## csvs that hade subject_id in hosp:\n",
    "services, procedures_icd, prescriptions, poe_detail, poe, pharmacy, microbiologyevents,labevents hcpcsevents, emar_detail, emar, \n",
    "## csvs that have neither in hosp:\n",
    "d_hcpcs, d_labitems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8ad6a",
   "metadata": {},
   "source": [
    "## all csvs in core have subject_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d0abb",
   "metadata": {},
   "source": [
    "## all in icu has subject_id except d_items.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf37c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_csv_hosp = ['d_icd_diagnoses', 'd_icd_procedures', 'diagnoses_icd', 'procedures_icd']\n",
    "sub_id_hosp = ['services', 'prescriptions','labevents', 'poe_detail', 'poe', 'pharmacy', 'microbiologyevents', 'hcpcsevents', 'emar_detail', 'emar']\n",
    "sub_id_core = ['admissions', 'patients', 'transfers']\n",
    "sub_id_icu = ['chartevents', 'datetimeevents', 'icustays', 'inputevents', 'outputevents', 'procedureevents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1dfca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in icd_csv_hosp:\n",
    "    path = \"mimic-iv-1.0/hosp/\"+csv\n",
    "    #df = pd.read_csv(path)\n",
    "    df = spark.read.csv(path+\".csv\", header=True)\n",
    "    df = df.filter(df.icd_code.isin(icd))\n",
    "    df.write.option('header', True).csv(path+\"_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in sub_id_hosp:\n",
    "    path = \"mimic-iv-1.0/hosp/\"+csv\n",
    "    #df = pd.read_csv(path)\n",
    "    df = spark.read.csv(path+\".csv\", header=True)\n",
    "    df = df.filter(df.subject_id.isin(subject_ids))\n",
    "    df.write.option('header', True).csv(path+\"_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1bc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in sub_id_core:\n",
    "    path = \"mimic-iv-1.0/core/\"+csv\n",
    "    #df = pd.read_csv(path)\n",
    "    df = spark.read.csv(path+\".csv\", header=True)\n",
    "    df = df.filter(df.subject_id.isin(subject_ids))\n",
    "    df.write.option('header', True).csv(path+\"_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44553ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in sub_id_icu:\n",
    "    path = \"mimic-iv-1.0/icu/\"+csv\n",
    "    #df = pd.read_csv(path)\n",
    "    df = spark.read.csv(path+\".csv\", header=True)\n",
    "    df = df.filter(df.subject_id.isin(subject_ids))\n",
    "    df.write.option('header', True).csv(path+\"_filtered.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
