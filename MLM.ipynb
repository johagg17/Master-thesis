{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d29a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import EHRDataset\n",
    "from model.tokenizer import EHRTokenizer\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from torch.utils.data import DataLoader\n",
    "from model.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1497fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918ea3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(params, config=None):\n",
    "    if config is None:\n",
    "        config = {\n",
    "            'lr': 3e-5,\n",
    "            'warmup_proportion': 0.1,\n",
    "            'weight_decay': 0.01\n",
    "        }\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in params if any(nd in n for nd in no_decay)], 'weight_decay': 0}\n",
    "    ]\n",
    "\n",
    "    optim = Bert.optimization.BertAdam(optimizer_grouped_parameters,\n",
    "                                       lr=config['lr'],\n",
    "                                       warmup=config['warmup_proportion'])\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7369ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:/Users/Johan/Documents/Skola/MasterThesis/Master-thesis/pre-processing/combined-csv-files.csv'\n",
    "path = 'processing/dataframe.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40da2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embedding'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        \n",
    "class TrainConfig(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3f7a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'max_seq_len': 64,\n",
    "    'max_age': 110,\n",
    "    'month': 1,\n",
    "    'age_symbol': None,\n",
    "    'min_visit': 5,\n",
    "    'gradient_accumulation_steps': 1\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 1,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'device': 'cpu' #change this to run on cuda #'cuda:0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2346aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2980cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107704"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc2793e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10028314</td>\n",
       "      <td>[Z3800, P2912, Z23, Q620, Z051, Z412, P284, P9...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10052351</td>\n",
       "      <td>[R0789, F10129, SEP]</td>\n",
       "      <td>[56, 56, 56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10092012</td>\n",
       "      <td>[Z051, Z23, Z3800, SEP]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10092020</td>\n",
       "      <td>[Z87891, Z8546, Z7901, G4089, I4820, Z8673, E8...</td>\n",
       "      <td>[69, 69, 69, 69, 69, 69, 69, 69, 69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10126895</td>\n",
       "      <td>[Z30430, O80, Z3A39, Z370, SEP]</td>\n",
       "      <td>[24, 24, 24, 24, 24]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id                                           icd_code  \\\n",
       "0    10028314  [Z3800, P2912, Z23, Q620, Z051, Z412, P284, P9...   \n",
       "1    10052351                               [R0789, F10129, SEP]   \n",
       "2    10092012                            [Z051, Z23, Z3800, SEP]   \n",
       "3    10092020  [Z87891, Z8546, Z7901, G4089, I4820, Z8673, E8...   \n",
       "4    10126895                    [Z30430, O80, Z3A39, Z370, SEP]   \n",
       "\n",
       "                                             age  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1                                   [56, 56, 56]  \n",
       "2                                   [0, 0, 0, 0]  \n",
       "3           [69, 69, 69, 69, 69, 69, 69, 69, 69]  \n",
       "4                           [24, 24, 24, 24, 24]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06debd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code_len'] = data['icd_code'].apply(lambda x: len(x))\n",
    "data['age_len'] = data['age'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369cc47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>age</th>\n",
       "      <th>code_len</th>\n",
       "      <th>age_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10028314</td>\n",
       "      <td>[Z3800, P2912, Z23, Q620, Z051, Z412, P284, P9...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10052351</td>\n",
       "      <td>[R0789, F10129, SEP]</td>\n",
       "      <td>[56, 56, 56]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10092012</td>\n",
       "      <td>[Z051, Z23, Z3800, SEP]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10092020</td>\n",
       "      <td>[Z87891, Z8546, Z7901, G4089, I4820, Z8673, E8...</td>\n",
       "      <td>[69, 69, 69, 69, 69, 69, 69, 69, 69]</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10126895</td>\n",
       "      <td>[Z30430, O80, Z3A39, Z370, SEP]</td>\n",
       "      <td>[24, 24, 24, 24, 24]</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107699</th>\n",
       "      <td>19837828</td>\n",
       "      <td>[Z3800, Z23, SEP]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107700</th>\n",
       "      <td>19910693</td>\n",
       "      <td>[I2510, D638, Z8619, J440, I739, I10, R0902, Z...</td>\n",
       "      <td>[64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 6...</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107701</th>\n",
       "      <td>19963063</td>\n",
       "      <td>[O081, D62, Z3A01, O99011, K661, O00102, SEP]</td>\n",
       "      <td>[35, 35, 35, 35, 35, 35, 35]</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107702</th>\n",
       "      <td>19979982</td>\n",
       "      <td>[Y92239, I70201, M109, Z006, N400, I120, I2510...</td>\n",
       "      <td>[83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 8...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107703</th>\n",
       "      <td>19989437</td>\n",
       "      <td>[I214, I25119, F17200, J9811, R0902, Z8249, J9...</td>\n",
       "      <td>[38, 38, 38, 38, 38, 38, 38, 38]</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107704 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id                                           icd_code  \\\n",
       "0         10028314  [Z3800, P2912, Z23, Q620, Z051, Z412, P284, P9...   \n",
       "1         10052351                               [R0789, F10129, SEP]   \n",
       "2         10092012                            [Z051, Z23, Z3800, SEP]   \n",
       "3         10092020  [Z87891, Z8546, Z7901, G4089, I4820, Z8673, E8...   \n",
       "4         10126895                    [Z30430, O80, Z3A39, Z370, SEP]   \n",
       "...            ...                                                ...   \n",
       "107699    19837828                                  [Z3800, Z23, SEP]   \n",
       "107700    19910693  [I2510, D638, Z8619, J440, I739, I10, R0902, Z...   \n",
       "107701    19963063      [O081, D62, Z3A01, O99011, K661, O00102, SEP]   \n",
       "107702    19979982  [Y92239, I70201, M109, Z006, N400, I120, I2510...   \n",
       "107703    19989437  [I214, I25119, F17200, J9811, R0902, Z8249, J9...   \n",
       "\n",
       "                                                      age  code_len  age_len  \n",
       "0           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]        15       15  \n",
       "1                                            [56, 56, 56]         3        3  \n",
       "2                                            [0, 0, 0, 0]         4        4  \n",
       "3                    [69, 69, 69, 69, 69, 69, 69, 69, 69]         9        9  \n",
       "4                                    [24, 24, 24, 24, 24]         5        5  \n",
       "...                                                   ...       ...      ...  \n",
       "107699                                          [0, 0, 0]         3        3  \n",
       "107700  [64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 6...        48       48  \n",
       "107701                       [35, 35, 35, 35, 35, 35, 35]         7        7  \n",
       "107702  [83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 8...        14       14  \n",
       "107703                   [38, 38, 38, 38, 38, 38, 38, 38]         8        8  \n",
       "\n",
       "[107704 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c4b1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EHRTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "359b123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dset = EHRDataset(data, max_len=train_params['max_len_seq'], tokenizer=tokenizer)\n",
    "trainload = DataLoader(dataset=Dset, batch_size=train_params['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15c0be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'vocab_size': len(tokenizer.getVoc('code').keys()), # number of disease + symbols for word embedding\n",
    "    'hidden_size': 288, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(tokenizer.getVoc('age').keys()), # number of vocab for age embedding\n",
    "    'max_position_embedding': train_params['max_len_seq'], # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.1, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 12, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.1, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cffed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = BertConfig(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1970c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3297975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107704"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62ed0975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "model = model.to(train_params['device'])\n",
    "optim = adam(params=list(model.named_parameters()), config=optim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc91b127",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 9.705232620239258 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14652/1949514255.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mage_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposi_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattMask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mage_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposi_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposi_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattMask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_lm_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\masterenv\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\masterenv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss_ = 0\n",
    "    for step, batch in enumerate(trainload):    \n",
    "        batch = tuple(t.to(train_params['device']) for t in batch)\n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, labels = batch \n",
    "        loss, pred, label = model(input_ids, age_ids = age_ids, seg_ids = segment_ids, posi_ids = posi_ids,attention_mask=attMask, masked_lm_labels=labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        if step % 200==0:\n",
    "            print(\"epoch: {}, loss: {} \".format(epoch, loss.item()))\n",
    "            \n",
    "        loss_ += loss.item()\n",
    "\n",
    "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        \n",
    "    print(\"Average loss {} after epoch {}\".format(loss_ / len(trainload), epoch))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495bf6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from processing.patient_extraction import *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
