{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5e6d03-c6a6-4c47-89c7-8238e87237ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba6d229-2037-43e0-8551-fdf1d53e7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a27ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import EHRDataset\n",
    "from model.tokenizer import EHRTokenizer\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from torch.utils.data import DataLoader\n",
    "from model.model import *\n",
    "from utils.config import *\n",
    "from utils.optimizer import adam\n",
    "from model.trainers import TrainerMLM\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "#from pytorch_lightning.strategies import DeepSpeedStrategy\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils.vocabulary import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347e301a-72ae-4b39-826c-4dffec8fe557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.10'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c177dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:/Users/Johan/Documents/Skola/MasterThesis/Master-thesis/pre-processing/combined-csv-files.csv'\n",
    "path_patients = '../data/datasets/readmission_data_synthea'\n",
    "path_prior = '../data/datasets/prior_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e1014c1-ab64-4a05-8fbc-9b4aacae2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapat = pd.read_parquet(path_patients)\n",
    "dataprior = pd.read_parquet(path_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b8544aa-e596-4017-b1e1-a4f7c72c36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datapat.merge(dataprior, on='subject_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "732f78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'max_seq_len': 32,\n",
    "    'gradient_accumulation_steps': 1\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 32,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'device': 'cuda' #change this to run on cuda #'cuda:0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc4ee4e-922b-4bae-896b-a5f608e3f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['subject_id'] = dataset['subject_id'].apply(lambda x: x.replace('-', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07e623b-c285-4ab2-8e76-a17334aa3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnos_codes = dataset['diagnos_code'].tolist()\n",
    "#med_codes = dataset['medication_code'].tolist()\n",
    "#diagnos_codes.extend(med_codes)\n",
    "#file_path = '../data/vocabularies/Synthea/snomedrxnorm'\n",
    "#write_codes_to_file(diagnos_codes, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7246e1f0-6d9e-4b6f-8775-fa46537ba62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ages = dataset['age'].tolist()\n",
    "#file_path = '../data/vocabularies/Synthea/age'\n",
    "#write_age_to_file(ages, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be625ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'code':'../data/vocabularies/Synthea/snomedrxnorm.npy',\n",
    "         'age':'../data/vocabularies/Synthea/age.npy'\n",
    "        }\n",
    "tokenizer = EHRTokenizer(task='MLM', filenames=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d869c1d-64fb-4731-a693-a91a6aceb9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.getVoc('code').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec6d8921-f627-4e78-85c6-7ae56f9d3f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.getVoc('age').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f01e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shallow\n",
    "model_config = {\n",
    "    'vocab_size': len(tokenizer.getVoc('code').keys()), # number of disease + symbols for word embedding\n",
    "    'hidden_size': 288, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(tokenizer.getVoc('age').keys()), # number of vocab for age embedding,\n",
    "    'gender_vocab_size': 3,\n",
    "    'max_position_embeddings': train_params['max_len_seq'], # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.1, # dropout rate\n",
    "    'num_hidden_layers': 4, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 6, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.1, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "    'use_prior':True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "914c04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = BertConfig(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcd16dcb-5eaf-4a46-8db9-445f4dce0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboarddir = '../logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f0a7a73-ec91-4ba5-aff2-b6eeb13dd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfold=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "232b963e-bdc8-4498-80a8-837d84a149b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "            max_epochs=5, \n",
    "            gpus=-1,\n",
    "            logger=pl.loggers.TensorBoardLogger(save_dir=tensorboarddir),\n",
    "            callbacks=[pl.callbacks.TQDMProgressBar()], \n",
    "            progress_bar_refresh_rate=1,\n",
    "            weights_summary=None, # Can be None, top or full\n",
    "            num_sanity_val_steps=10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2146eeb6-710c-47b6-ba79-9468f097a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26515286-8335-4de3-8835-bfb0698aa1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traind = EHRDataset(trainset, max_len=train_params['max_len_seq'], tokenizer=tokenizer)\n",
    "testd = EHRDataset(testset, max_len=train_params['max_len_seq'], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eec11dba-0dc8-45e3-a8b9-12c03d93005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(traind, batch_size=32, shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testd, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25663a9f-d2ca-4ac6-8ec8-e366846e4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM(conf) #BertForMaskedLM(conf)\n",
    "params = list(model.named_parameters())\n",
    "optim = adam(params, optim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1727d416-ced6-440c-8064-2386a282f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210a0aa96bf3462a8422db66cbc3f01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regterm\n",
      "tensor(2.4809, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4823, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4934, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4742, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.5018, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4850, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4725, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4549, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4532, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4854, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4745, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4685, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4719, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.5034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4820, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4729, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4955, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4906, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4788, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4739, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4790, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4850, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4611, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4824, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4668, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4657, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4711, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4984, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4837, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4786, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4657, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4575, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4830, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4666, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4770, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4676, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4881, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4902, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4795, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4589, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4910, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.5014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4807, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4936, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4789, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4843, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4781, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4976, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4747, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4702, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4995, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4934, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4716, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4808, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4756, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4933, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4850, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4837, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4757, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4653, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4940, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4768, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4929, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4589, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4977, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4737, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4904, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4705, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4664, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4754, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4499, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4845, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4889, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4717, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4919, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4946, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4682, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4768, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4684, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4778, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4720, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4796, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4623, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4915, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4904, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4808, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4881, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4732, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4729, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4686, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4835, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4701, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4665, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4832, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4849, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4755, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4644, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4705, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4822, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4681, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4887, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4814, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4943, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4647, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4901, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4556, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4670, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4637, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4846, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4657, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "regterm\n",
      "tensor(2.4473, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6b55305ef740faae9dca36a423149a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 23it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regterm\n",
      "tensor(0.0188, device='cuda:0')\n",
      "regterm\n",
      "tensor(0.0183, device='cuda:0')\n",
      "regterm\n",
      "tensor(0.0188, device='cuda:0')\n",
      "regterm\n",
      "tensor(0.0177, device='cuda:0')\n",
      "regterm\n",
      "tensor(0.0188, device='cuda:0')\n",
      "regterm\n",
      "tensor(0.0180, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "patienttrajectory = TrainerMLM(model, optim, optim_param, 0.001)\n",
    "\n",
    "trainer.fit(\n",
    "    patienttrajectory, \n",
    "    train_dataloaders=trainloader,\n",
    ");\n",
    "\n",
    "predictions = trainer.predict(patienttrajectory, dataloaders=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bf4cc3b-d8b9-42cb-834a-85be31a046e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.986776828573287"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_acc = sum([ stats['precision'] for stats in predictions ]) / len(predictions)\n",
    "avg_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3d866-9443-4e10-8c15-f2e90206a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../saved_models/MLM/deep_notsuffled'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0b4a3-d2f2-4eca-aab3-f0dc183f358a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is for the crossval, might not be runnable since we have done some debugging\n",
    "\n",
    "'''\n",
    "for fold,(train_idx,test_idx) in enumerate(kfold.split(data)):\n",
    "    print('------------fold no---------{}----------------------'.format(fold))\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "            max_epochs=5, \n",
    "            gpus=-1,\n",
    "            logger=pl.loggers.TensorBoardLogger(save_dir=tensorboarddir),\n",
    "            callbacks=[pl.callbacks.progress.TQDMProgressBar()], \n",
    "            progress_bar_refresh_rate=1,\n",
    "            weights_summary=None, # Can be None, top or full\n",
    "            num_sanity_val_steps=10,\n",
    "        )\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=train_params['batch_size'], sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=train_params['batch_size'], sampler=test_subsampler)\n",
    "    \n",
    "    model = BertForMaskedLM(conf) #BertForMaskedLM(conf)\n",
    "    params = list(model.named_parameters())\n",
    "    optim = adam(params, optim_param)\n",
    "    \n",
    "    patienttrajectory = PatientTrajectoryPredictor(model, optim, optim_param, metrics=True)\n",
    "    \n",
    "    trainer.fit(\n",
    "        patienttrajectory, \n",
    "        train_dataloader=trainloader,\n",
    "    );\n",
    "  \n",
    "    predictions = trainer.predict(patienttrajectory, dataloaders=testloader)\n",
    "    avg_acc = sum([ stats['Precision'] for stats in predictions ]) / len(predictions)\n",
    "    \n",
    "    if avg_acc > best_test:\n",
    "        PATH = '../saved_models/Shallow_unsuffled{}'.format(fold)\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        best_test = avg_acc\n",
    "        \n",
    "    print(\"Average Test precision for fold {}: {} \".format(fold, avg_acc))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63661910-f1aa-439e-947a-8f0764ef5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../saved_models/Shallow_unsuffled{}'.format(fold)\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a7d25-622a-4ae1-98d8-608ce46df233",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b162a1-fbff-4588-93b6-4e6d2d0d5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(allacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c02ae1-a2db-4688-a280-7349eed0e58d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing with BEHRTs training approach (without pytorch lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bedfb1-7994-4e69-8f7b-9592a03fc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35e7f0-59bd-47c4-907f-a1cdea876acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def cal_acc(label, pred):\n",
    "    logs = nn.LogSoftmax()\n",
    "    label=label.cpu().numpy()\n",
    "    ind = np.where(label!=-1)[0]\n",
    "    truepred = pred.detach().cpu().numpy()\n",
    "    truepred = truepred[ind]\n",
    "    truelabel = label[ind]\n",
    "    truepred = logs(torch.tensor(truepred))\n",
    "    outs = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
    "    \n",
    "   # print(\"Truelabel:\")\n",
    "   # print(truelabel)\n",
    "    \n",
    "   # print(\"Output:\")\n",
    "   # print(outs)\n",
    "    precision = skm.precision_score(truelabel, outs, average='micro')\n",
    "    return precision\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42dc98-e930-4cfc-9fa3-02685e197ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf = BertConfig(model_config)\n",
    "#model = BertForMaskedLM(conf) \n",
    "#model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455eeada-6cfe-4898-a14f-f5f91badfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = list(model.named_parameters())\n",
    "#optim = adam(params, optim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036d132-371f-452b-8d0b-8c7a9a433a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train(e, loader):\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt= 0\n",
    "    start = time.time()\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        cnt +=1\n",
    "        batch = tuple(t.to(train_params['device']) for t in batch)\n",
    "        age_ids, gender_ids, input_ids, posi_ids, segment_ids, attMask, masked_label, _ = batch\n",
    "        #print()\n",
    "        loss, pred, label = model(input_ids, age_ids, gender_ids, segment_ids, posi_ids,attention_mask=attMask, labels=masked_label)\n",
    "        if global_params['gradient_accumulation_steps'] >1:\n",
    "            loss = loss/global_params['gradient_accumulation_steps']\n",
    "        loss.backward()\n",
    "        \n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "        \n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        if step % 200==0:\n",
    "            print(\"epoch: {}\\t| cnt: {}\\t|Loss: {}\\t| precision: {:.4f}\\t| time: {:.2f}\".format(e, cnt, temp_loss/2000, cal_acc(label, pred), time.time()-start))\n",
    "            temp_loss = 0\n",
    "            start = time.time()\n",
    "            \n",
    "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "   #print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "    #model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "    #create_folder(file_config['model_path'])\n",
    "    #output_model_file = os.path.join(file_config['model_path'], file_config['model_name'])\n",
    "\n",
    "    #torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        \n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab456b-d788-49db-94a5-d906169605d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1198cf-4a54-407c-982e-857be9056627",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = EHRDataset(trainset, max_len=train_params['max_len_seq'], tokenizer=tokenizer)\n",
    "trainload = DataLoader(dataset=trainset, batch_size=train_params['batch_size'], shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c5a5f-7142-44d5-b376-3eac2d9b2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e17cb07-a7e5-4685-9553-ae8473d74c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(100):\n",
    "    loss, timecost = train(e, trainload)\n",
    "    loss = loss / len(trainload)\n",
    "    \n",
    "    print(\"Loss after epoch {}: {}\".format(e, loss))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e98b64-99d9-47cd-b236-a4b5f7a0f40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc6c58-2a60-4890-83c3-e16e70d4a337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
