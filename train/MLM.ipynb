{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b5e6d03-c6a6-4c47-89c7-8238e87237ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bba6d229-2037-43e0-8551-fdf1d53e7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59a27ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import EHRDataset\n",
    "from model.tokenizer import EHRTokenizer\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from torch.utils.data import DataLoader\n",
    "from model.model2 import *\n",
    "#from utils.config import BertConfig\n",
    "from model.trainer import PatientTrajectoryPredictor\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "053ea6ff-ed4c-49e3-9517-2f47795b5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b75076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f7974f8-62e3-4039-adc2-a8ddf30786cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f185f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(params, config=None):\n",
    "    if config is None:\n",
    "        config = {\n",
    "            'lr': 3e-5,\n",
    "            'warmup_proportion': 0.1,\n",
    "            'weight_decay': 0.01\n",
    "        }\n",
    "        \n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in params if any(nd in n for nd in no_decay)], 'weight_decay': 0}\n",
    "    ]\n",
    "\n",
    "    optim = Bert.optimization.BertAdam(optimizer_grouped_parameters,\n",
    "                                       lr=config['lr'],\n",
    "                                       warmup=config['warmup_proportion'])\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c177dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:/Users/Johan/Documents/Skola/MasterThesis/Master-thesis/pre-processing/combined-csv-files.csv'\n",
    "path = '../processing/readmission_data_ccsr_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce83c0-79b8-4467-9fe7-59ea8085ae70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "835899dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainConfig(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "732f78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'max_seq_len': 32,\n",
    "    'gradient_accumulation_steps': 1\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'device': 'cuda' #change this to run on cuda #'cuda:0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "456de5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0345b2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>label</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>ccsr</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_abuse</th>\n",
       "      <th>tobacco_abuse</th>\n",
       "      <th>ndc</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10008245</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[[S32391A, E870, F72, G40909, R509, J45909, M8...</td>\n",
       "      <td>[[INJ003, END011, MBD014, NVS009, SYM002, RSP0...</td>\n",
       "      <td>[47.0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[[69543013120, 904645561, 54482014407, 6655300...</td>\n",
       "      <td>[26674944]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10031358</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[E11618, M86179, I96, E871, L97509, N179, E11...</td>\n",
       "      <td>[[END003, MUS002, CIR028, END011, SKN004, GEN0...</td>\n",
       "      <td>[62.0, 63.0, 64.0, 64.0, 65.0, 65.0]</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[63323026201, 71015892, 51079045420, 74706811...</td>\n",
       "      <td>[27421511, 28279098, 24522342, 29498981, 29887...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id               label  \\\n",
       "0    10008245                 [0]   \n",
       "1    10031358  [0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                            icd_code  \\\n",
       "0  [[S32391A, E870, F72, G40909, R509, J45909, M8...   \n",
       "1  [[E11618, M86179, I96, E871, L97509, N179, E11...   \n",
       "\n",
       "                                                ccsr  \\\n",
       "0  [[INJ003, END011, MBD014, NVS009, SYM002, RSP0...   \n",
       "1  [[END003, MUS002, CIR028, END011, SKN004, GEN0...   \n",
       "\n",
       "                                    age       alcohol_abuse  \\\n",
       "0                                [47.0]                 [0]   \n",
       "1  [62.0, 63.0, 64.0, 64.0, 65.0, 65.0]  [1, 1, 0, 0, 0, 0]   \n",
       "\n",
       "        tobacco_abuse                                                ndc  \\\n",
       "0                 [0]  [[69543013120, 904645561, 54482014407, 6655300...   \n",
       "1  [0, 0, 0, 0, 0, 0]  [[63323026201, 71015892, 51079045420, 74706811...   \n",
       "\n",
       "                                             hadm_id gender  \n",
       "0                                         [26674944]      M  \n",
       "1  [27421511, 28279098, 24522342, 29498981, 29887...      M  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5242cfd3-2534-4349-988a-6d4dc8532e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170296"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be625ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EHRTokenizer(task='MLM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2d869c1d-64fb-4731-a693-a91a6aceb9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.getVoc('code').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec6d8921-f627-4e78-85c6-7ae56f9d3f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.getVoc('age').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1f01e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shallow\n",
    "'''\n",
    "model_config = {\n",
    "    'vocab_size': len(tokenizer.getVoc('code').keys()), # number of disease + symbols for word embedding\n",
    "    'hidden_size': 300, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(tokenizer.getVoc('age').keys()), # number of vocab for age embedding,\n",
    "    'gender_vocab_size': 3,\n",
    "    'max_position_embeddings': train_params['max_len_seq'], # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.1, # dropout rate\n",
    "    'num_hidden_layers': 2, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 4, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.1, # multi-head attention dropout rate\n",
    "    'intermediate_size': 300, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "}\n",
    "'''\n",
    "#Deep\n",
    "'''\n",
    "model_config = {\n",
    "    'vocab_size': len(tokenizer.getVoc('code').keys()), # number of disease + symbols for word embedding\n",
    "    'hidden_size': 300, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(tokenizer.getVoc('age').keys()), # number of vocab for age embedding,\n",
    "    'gender_vocab_size': 3,\n",
    "    'max_position_embeddings': train_params['max_len_seq'], # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.1, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 12, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.1, # multi-head attention dropout rate\n",
    "    'intermediate_size': 300, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "}\n",
    "'''\n",
    "\n",
    "## Deeper\n",
    "model_config = {\n",
    "    'vocab_size': len(tokenizer.getVoc('code').keys()), # number of disease + symbols for word embedding\n",
    "    'hidden_size': 300, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(tokenizer.getVoc('age').keys()), # number of vocab for age embedding,\n",
    "    'gender_vocab_size': 3,\n",
    "    'max_position_embeddings': train_params['max_len_seq'], # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.1, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 12, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.1, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3c869175-5363-41f5-8e69-0ce8aca95579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.gender_vocab_size = config.get('gender_vocab_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "914c04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = BertConfig(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dcd16dcb-5eaf-4a46-8db9-445f4dce0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboarddir = '../logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f0a7a73-ec91-4ba5-aff2-b6eeb13dd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "76dfd77e-0e65-43a8-bb34-d05555b6606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "allacc = []\n",
    "dataset = EHRDataset(data, max_len=train_params['max_len_seq'], tokenizer=tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3c0c9fd3-7d4f-4804-a7ee-ced23ad6a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test = -10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "232b963e-bdc8-4498-80a8-837d84a149b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "            max_epochs=20, \n",
    "            gpus=-1,\n",
    "            logger=pl.loggers.TensorBoardLogger(save_dir=tensorboarddir),\n",
    "            callbacks=[pl.callbacks.progress.TQDMProgressBar()], \n",
    "            progress_bar_refresh_rate=1,\n",
    "            weights_summary=None, # Can be None, top or full\n",
    "            num_sanity_val_steps=10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2146eeb6-710c-47b6-ba79-9468f097a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "26515286-8335-4de3-8835-bfb0698aa1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traind = EHRDataset(trainset, max_len=train_params['max_len_seq'], tokenizer=tokenizer)\n",
    "testd = EHRDataset(testset, max_len=train_params['max_len_seq'], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eec11dba-0dc8-45e3-a8b9-12c03d93005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(traind, batch_size=train_params['batch_size'], shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testd, batch_size=train_params['batch_size'], shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "25663a9f-d2ca-4ac6-8ec8-e366846e4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM(conf) #BertForMaskedLM(conf)\n",
    "params = list(model.named_parameters())\n",
    "optim = adam(params, optim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1727d416-ced6-440c-8064-2386a282f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|███████████████████████████████████████████████| 1863/1863 [01:41<00:00, 18.29it/s, loss=3.94, v_num=183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 1863it [00:12, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "patienttrajectory = PatientTrajectoryPredictor(model, optim, optim_param, metrics=True)\n",
    "\n",
    "trainer.fit(\n",
    "    patienttrajectory, \n",
    "    train_dataloader=trainloader,\n",
    ");\n",
    "\n",
    "predictions = trainer.predict(patienttrajectory, dataloaders=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5bf4cc3b-d8b9-42cb-834a-85be31a046e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15472233202380856"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_acc = sum([ stats['Precision'] for stats in predictions ]) / len(predictions)\n",
    "avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cca3d866-9443-4e10-8c15-f2e90206a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../saved_models/MLM/deep_notsuffled'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4a0b4a3-d2f2-4eca-aab3-f0dc183f358a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "t_total value of -1 results in schedule not being applied\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold no---------0----------------------\n",
      "Epoch 4: 100%|██████████████████████████████████████████████| 27248/27248 [13:42<00:00, 33.12it/s, loss=4.11, v_num=155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: 27248it [00:35, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../saved_models/Shallow_unsuffled/best_model0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3337746/257821522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mavg_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../saved_models/Shallow_unsuffled/best_model{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mbest_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/masterenv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/masterenv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/masterenv/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../saved_models/Shallow_unsuffled/best_model0'"
     ]
    }
   ],
   "source": [
    "# This is for the crossval, might not be runnable since we have done some debugging\n",
    "\n",
    "'''\n",
    "for fold,(train_idx,test_idx) in enumerate(kfold.split(data)):\n",
    "    print('------------fold no---------{}----------------------'.format(fold))\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "            max_epochs=5, \n",
    "            gpus=-1,\n",
    "            logger=pl.loggers.TensorBoardLogger(save_dir=tensorboarddir),\n",
    "            callbacks=[pl.callbacks.progress.TQDMProgressBar()], \n",
    "            progress_bar_refresh_rate=1,\n",
    "            weights_summary=None, # Can be None, top or full\n",
    "            num_sanity_val_steps=10,\n",
    "        )\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=train_params['batch_size'], sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, batch_size=train_params['batch_size'], sampler=test_subsampler)\n",
    "    \n",
    "    model = BertForMaskedLM(conf) #BertForMaskedLM(conf)\n",
    "    params = list(model.named_parameters())\n",
    "    optim = adam(params, optim_param)\n",
    "    \n",
    "    patienttrajectory = PatientTrajectoryPredictor(model, optim, optim_param, metrics=True)\n",
    "    \n",
    "    trainer.fit(\n",
    "        patienttrajectory, \n",
    "        train_dataloader=trainloader,\n",
    "    );\n",
    "  \n",
    "    predictions = trainer.predict(patienttrajectory, dataloaders=testloader)\n",
    "    avg_acc = sum([ stats['Precision'] for stats in predictions ]) / len(predictions)\n",
    "    \n",
    "    if avg_acc > best_test:\n",
    "        PATH = '../saved_models/Shallow_unsuffled{}'.format(fold)\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        best_test = avg_acc\n",
    "        \n",
    "    print(\"Average Test precision for fold {}: {} \".format(fold, avg_acc))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63661910-f1aa-439e-947a-8f0764ef5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../saved_models/Shallow_unsuffled{}'.format(fold)\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d98a7d25-622a-4ae1-98d8-608ce46df233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1513192108874815"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b162a1-fbff-4588-93b6-4e6d2d0d5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(allacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c02ae1-a2db-4688-a280-7349eed0e58d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing with BEHRTs training approach (without pytorch lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bedfb1-7994-4e69-8f7b-9592a03fc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35e7f0-59bd-47c4-907f-a1cdea876acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def cal_acc(label, pred):\n",
    "    logs = nn.LogSoftmax()\n",
    "    label=label.cpu().numpy()\n",
    "    ind = np.where(label!=-1)[0]\n",
    "    truepred = pred.detach().cpu().numpy()\n",
    "    truepred = truepred[ind]\n",
    "    truelabel = label[ind]\n",
    "    truepred = logs(torch.tensor(truepred))\n",
    "    outs = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
    "    \n",
    "   # print(\"Truelabel:\")\n",
    "   # print(truelabel)\n",
    "    \n",
    "   # print(\"Output:\")\n",
    "   # print(outs)\n",
    "    precision = skm.precision_score(truelabel, outs, average='micro')\n",
    "    return precision\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42dc98-e930-4cfc-9fa3-02685e197ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf = BertConfig(model_config)\n",
    "#model = BertForMaskedLM(conf) \n",
    "#model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455eeada-6cfe-4898-a14f-f5f91badfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = list(model.named_parameters())\n",
    "#optim = adam(params, optim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036d132-371f-452b-8d0b-8c7a9a433a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train(e, loader):\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt= 0\n",
    "    start = time.time()\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        cnt +=1\n",
    "        batch = tuple(t.to(train_params['device']) for t in batch)\n",
    "        age_ids, gender_ids, input_ids, posi_ids, segment_ids, attMask, masked_label, _ = batch\n",
    "        #print()\n",
    "        loss, pred, label = model(input_ids, age_ids, gender_ids, segment_ids, posi_ids,attention_mask=attMask, labels=masked_label)\n",
    "        if global_params['gradient_accumulation_steps'] >1:\n",
    "            loss = loss/global_params['gradient_accumulation_steps']\n",
    "        loss.backward()\n",
    "        \n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "        \n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        if step % 200==0:\n",
    "            print(\"epoch: {}\\t| cnt: {}\\t|Loss: {}\\t| precision: {:.4f}\\t| time: {:.2f}\".format(e, cnt, temp_loss/2000, cal_acc(label, pred), time.time()-start))\n",
    "            temp_loss = 0\n",
    "            start = time.time()\n",
    "            \n",
    "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "   #print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "    #model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "    #create_folder(file_config['model_path'])\n",
    "    #output_model_file = os.path.join(file_config['model_path'], file_config['model_name'])\n",
    "\n",
    "    #torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        \n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab456b-d788-49db-94a5-d906169605d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1198cf-4a54-407c-982e-857be9056627",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = EHRDataset(trainset, max_len=train_params['max_len_seq'], tokenizer=tokenizer)\n",
    "trainload = DataLoader(dataset=trainset, batch_size=train_params['batch_size'], shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c5a5f-7142-44d5-b376-3eac2d9b2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e17cb07-a7e5-4685-9553-ae8473d74c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(100):\n",
    "    loss, timecost = train(e, trainload)\n",
    "    loss = loss / len(trainload)\n",
    "    \n",
    "    print(\"Loss after epoch {}: {}\".format(e, loss))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e98b64-99d9-47cd-b236-a4b5f7a0f40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc6c58-2a60-4890-83c3-e16e70d4a337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
